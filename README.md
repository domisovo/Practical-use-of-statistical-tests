# Practical-use-of-statistical-tests
A group project done in R that dealt with statistical testing.
1. We define any discrete one-dimensional random variable and draw samples of various sizes from its distribution. We then compare the accuracy of the point estimates for mean, variance, skewness, and kurtosis depending on how many observations were sampled. Please determine the theoretical values of the distribution based on the definition/formula (you can use Excel or write a function in R). Comparison can be done visually (charts) or by reporting errors for different sample sizes.

2. We show the operation of the central limit theorem in simulation. This can be done, for example, by generating more and more random samples from non-normal distributions and showing how their sum approaches the normal distribution. It can also be done in another way, e.g. by simulating an increasing number of dice/coin throws and showing the features of the distribution of their sum/average. The study can be performed visually (e.g. plots of the estimated density function, quantile-quantile plots), but also computationally (normality test statistics).

3. We check the operation of normality tests. We draw a sample from a selected non-normal distribution and using selected normality tests (at least two) we determine how often for a given significance level the test result is false (there are no grounds to reject the null hypothesis about the normality of the distribution). Then we draw a sample from a normal distribution and determine how often the result is false (there are grounds for rejecting the null hypothesis about the normality of the distribution). Then we modify the number of trials and repeat the experiments. What relationships can be determined for the power of normality tests?

4. We check the operation of the Student's t-test for one sample. We draw a sample from any distribution with a known mean μ of 0 and test it for H0: μ = 0. How often is the null hypothesis rejected? Then we modify the distribution so that its mean is more and more different from 0, we draw the sample again and perform the test again. We repeat the experiment, checking how the test statistic (and p-value) depend on μ of the distribution from which the sample came (i.e. on the difference: μ - 0). Then, for a fixed mean of the distribution, we manipulate its standard deviation and see how the test results change with different levels of standard deviation.
